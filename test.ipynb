{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"b\": shape (1, 234), type \"|O\">\n",
      "<HDF5 dataset \"CA\": shape (1, 175), type \"|O\">\n",
      "<HDF5 dataset \"oU\": shape (1, 238), type \"|O\">\n",
      "<HDF5 dataset \"hlb\": shape (1, 114), type \"|O\">\n",
      "<HDF5 dataset \"ayb\": shape (1, 178), type \"|O\">\n",
      "<HDF5 dataset \"hSb\": shape (1, 47), type \"|O\">\n",
      "<HDF5 dataset \"BXb\": shape (1, 190), type \"|O\">\n",
      "<HDF5 dataset \"5ic\": shape (1, 170), type \"|O\">\n",
      "<HDF5 dataset \"hCc\": shape (1, 171), type \"|O\">\n",
      "<HDF5 dataset \"BVc\": shape (1, 36), type \"|O\">\n",
      "<HDF5 dataset \"GZc\": shape (1, 232), type \"|O\">\n",
      "<HDF5 dataset \"Tpd\": shape (1, 198), type \"|O\">\n",
      "<HDF5 dataset \"gMd\": shape (1, 36), type \"|O\">\n",
      "<HDF5 dataset \"lQd\": shape (1, 247), type \"|O\">\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"lQd\": shape (1, 247), type \"|O\">"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "dir_path=\"/home/amos/haitun/pycode/\"#os.path.dirname(os.path.abspath())\n",
    "\n",
    "# Open the MATLAB v7.3 file using h5py\n",
    "dataset = h5py.File(os.path.join(dir_path,'source/matlab/savedData.mat'), 'r')\n",
    "\n",
    "# Read the dataset from the file\n",
    "sample_list = dataset['sample_list']\n",
    "for samples_ref in sample_list[0]:\n",
    "    dataset[samples_ref]\n",
    "\n",
    "dataset[samples_ref]\n",
    "# dataset_list = torch.tensor(dataset[:])\n",
    "# # Close the file\n",
    "# mat_file.close()\n",
    "\n",
    "# np.array(dataset_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(dataset.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'trajectory_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/haitun/pycode/test.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dataframe\u001b[39m=\u001b[39mmat_contents[\u001b[39m\"\u001b[39;49m\u001b[39mtrajectory_list\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(dataframe[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dataframe\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mKeyError\u001b[0m: 'trajectory_list'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/haitun/pycode/test.ipynb 单元格 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mtest.npy\u001b[39m\u001b[39m\"\u001b[39m,dataframe)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.save(\"test.npy\",dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'aeon.utils' from '/home/amos/anaconda3/envs/haitun/lib/python3.8/site-packages/aeon/utils/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import aeon\n",
    "X=np.ones([5,6,7])\n",
    "aeon.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 26)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from aeon.transformations.collection import DWTTransformer\n",
    "import numpy as np\n",
    "data = np.array([[[1,2,3,4,5,6,7,8,9,10]],[[5,5,5,5,5,5,5,5,5,5]]])\n",
    "dwt = DWTTransformer(n_levels=20)\n",
    "data2 = dwt.fit_transform(data)\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0, device='cuda:0')\n",
      "tensor(1, device='cuda:0')\n",
      "tensor(4, device='cuda:0')\n",
      "tensor(9, device='cuda:0')\n",
      "tensor(16, device='cuda:0')\n",
      "tensor(25, device='cuda:0')\n",
      "tensor(36, device='cuda:0')\n",
      "tensor(49, device='cuda:0')\n",
      "tensor(64, device='cuda:0')\n",
      "tensor(81, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "def _kinetic_feature(single_sample):\n",
    "    # 在这加入到你的计算逻辑\n",
    "    result = single_sample ** 2\n",
    "    # 假设这个过程非常的费时\n",
    "    time.sleep(2)  \n",
    "    return result\n",
    "\n",
    "def parallel_execution(samples):\n",
    "    streams = []\n",
    "    results = []\n",
    "    # 创建一个CUDA流来为每个样本运行_kinetic_feature函数\n",
    "    for i in range(len(samples)):\n",
    "        streams.append(torch.cuda.Stream())\n",
    "        \n",
    "    for i, sample in enumerate(samples):\n",
    "        with torch.cuda.stream(streams[i]):\n",
    "            result = _kinetic_feature(sample)\n",
    "            results.append(result)\n",
    "            \n",
    "    # 等待所有流的操作完成\n",
    "    for i in range(len(samples)):\n",
    "        torch.cuda.current_stream().wait_stream(streams[i])\n",
    "    \n",
    "    return results\n",
    "\n",
    "cuda_samples = [torch.tensor(i, device='cuda') for i in range(10)]\n",
    "results = parallel_execution(cuda_samples)\n",
    "\n",
    "# 打印结果\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50,\n",
       "  0,\n",
       "  tensor([-1.6923, -0.1544,  1.9792, -1.0376,  0.4598,  0.9939, -0.4259,  0.3254,\n",
       "          -1.0183, -0.6959,  1.8755, -0.2923,  0.1903,  1.9563,  0.2392,  0.6282,\n",
       "           0.4556,  2.2616,  0.5598, -0.1053,  0.0183,  1.8638,  1.7166, -1.6367,\n",
       "          -0.2212, -1.1999, -0.2649, -1.5602,  0.1270, -1.1239, -2.0969, -0.5352,\n",
       "           0.0666,  0.7322,  0.3686,  0.1283, -1.3826,  1.7035, -0.0280,  0.3705,\n",
       "           0.2679,  3.4676, -0.0299, -0.8803,  0.2812, -0.3721,  0.1177, -2.5318,\n",
       "           0.1107,  1.4310])),\n",
       " (50,\n",
       "  3,\n",
       "  tensor([ 0.3066, -0.6730, -0.4274,  1.5191,  0.9963,  0.8142, -1.2502,  1.7890,\n",
       "           0.9502, -0.9045, -0.1636,  0.9384,  0.8782,  1.8705, -1.0843, -0.2210,\n",
       "          -0.5122,  0.6798, -0.0990, -2.7825,  0.1450,  1.6235,  0.4835, -1.0989,\n",
       "          -0.1385,  1.5020,  0.6848, -0.7145, -0.3568, -0.6627, -2.4854,  0.2502,\n",
       "           1.0837,  0.6952,  0.5972, -0.7339, -0.7667,  0.6331,  3.2073, -0.5579,\n",
       "           0.4174,  1.5318, -0.9855,  1.0638,  1.8190,  0.6417, -0.2605,  1.2081,\n",
       "          -0.3126,  3.3920])),\n",
       " (100,\n",
       "  1,\n",
       "  tensor([-1.1530,  0.4630, -0.5929, -0.3334, -1.5337, -0.3761, -0.4264,  0.6236,\n",
       "           0.7886,  0.5523,  0.0264,  0.1156, -0.3783, -0.6941, -0.0393, -1.6394,\n",
       "          -0.5846, -0.2359, -2.0743,  0.2484, -0.2625,  0.4787, -0.3564, -0.6270,\n",
       "          -0.0405, -0.9391, -0.4962, -0.8158, -0.3366, -1.1052, -0.9559, -0.6657,\n",
       "          -1.4685,  0.5117, -0.8488, -1.2464,  1.1677, -0.1994, -0.3418,  0.1849,\n",
       "          -0.2734, -0.7778,  0.3882, -1.1622,  0.0240,  0.7290, -1.4227,  0.2744,\n",
       "          -0.7629,  0.7817,  1.9479, -0.9582,  0.3567,  0.3388,  0.8410, -0.5682,\n",
       "           0.8118,  0.4415,  1.2033, -0.5356, -0.6253,  0.2633,  0.2636, -0.3777,\n",
       "           0.2874, -1.4015,  0.0504, -0.8909, -0.8847, -0.8191, -1.6529, -1.3088,\n",
       "          -0.7258,  0.1886,  0.6368,  1.0927,  3.2895, -1.8885, -0.1930,  0.0679,\n",
       "          -0.4479, -0.1354,  1.2434,  0.8896,  0.1481,  0.9528,  1.1196, -0.6375,\n",
       "          -0.2409,  0.3265, -0.6539,  0.4064,  0.4705,  0.0406,  0.3813, -0.2769,\n",
       "           1.6197, -1.1258, -0.0280, -0.5829])),\n",
       " (100,\n",
       "  4,\n",
       "  tensor([-0.4289, -0.5857,  0.3087, -1.2354,  0.8339, -0.4785, -0.4903, -0.7100,\n",
       "           0.0330,  0.0095,  1.3909, -0.3980,  1.3599, -0.2485, -0.4188, -0.1988,\n",
       "          -0.4136,  0.8919, -0.7887, -0.0146, -1.3846,  0.6869,  1.6992, -1.4809,\n",
       "          -0.1995,  0.7767, -0.2773,  0.1262, -0.6973,  0.2658, -1.2218,  0.6540,\n",
       "          -0.0215,  0.1941, -0.9657, -0.8268,  0.4618, -0.8658, -0.6027, -0.2678,\n",
       "          -0.9412, -1.1018, -0.3356,  0.9398, -2.0245,  1.0160,  0.1403,  0.0909,\n",
       "           0.9410, -0.1355, -1.5521,  0.0356,  0.4971,  0.9003,  1.4676,  0.3930,\n",
       "          -0.7113,  1.3270,  0.2109,  0.3563,  1.0695,  0.5034, -1.4095,  0.4734,\n",
       "           0.7605,  1.3122, -1.1689,  0.5824,  1.0899,  1.8018,  0.6538,  0.7158,\n",
       "           0.0653, -0.7026,  0.1878,  0.2457, -1.0392, -0.1742, -0.2410, -1.4499,\n",
       "           1.4318,  1.0092,  1.7431,  0.1464, -1.0243, -0.1314, -0.0052,  0.8813,\n",
       "          -0.6435, -0.6564, -1.0936, -1.1467, -1.4814, -0.3263, -0.2972,  0.2717,\n",
       "          -1.4997,  1.3772,  0.1853, -1.0750])),\n",
       " (150,\n",
       "  2,\n",
       "  tensor([ 0.4838,  0.2658,  1.3024,  0.4106,  0.7116,  0.3653,  1.2458, -0.9710,\n",
       "           0.3391, -0.1687, -0.4162,  0.6151,  0.1239, -0.8320, -0.0604, -0.1333,\n",
       "           1.2928,  1.1973, -0.3993,  1.4110, -1.8357,  0.0777,  0.4868,  0.7616,\n",
       "           0.2375,  0.4388, -1.2297,  0.7876,  0.6069,  0.7602, -0.7531,  0.3163,\n",
       "          -1.1307,  0.3194,  0.4733, -1.6075,  0.4613,  0.2316, -0.5192,  2.0695,\n",
       "          -0.3868,  1.1122, -0.6432,  1.4688, -0.2694,  0.8179,  0.2891, -0.4286,\n",
       "          -0.2077,  1.3917, -0.8775, -1.3784, -0.8770,  0.3631, -0.1439,  0.4794,\n",
       "           1.7795,  0.8811, -0.6582,  0.2229, -1.1269, -0.5766,  1.4305, -0.5890,\n",
       "           0.1710, -0.3207,  0.1703,  0.8670, -1.1666, -2.5756, -0.1512, -0.8443,\n",
       "           0.4056,  1.9162,  0.6585,  0.4617, -0.8121,  0.8601, -0.0343, -0.5251,\n",
       "          -1.3068,  0.8029,  0.8287, -1.0005, -0.3523, -0.1270, -0.9931, -0.1852,\n",
       "           1.1743,  0.6784, -0.2494,  1.3920, -0.6125, -0.0744, -0.0660,  0.8427,\n",
       "          -0.0728,  0.2515,  0.6648,  0.4393, -1.0885,  0.3600, -0.6955, -0.1181,\n",
       "          -0.2762, -0.0309, -0.7088,  2.2848, -1.0196,  1.2301,  0.1906,  0.5920,\n",
       "          -1.3232,  0.2147, -0.0989,  0.7025, -2.0134, -0.7358,  0.4744, -0.7162,\n",
       "           0.0119, -0.7050, -0.1172,  0.1502,  1.5162,  0.4613,  0.8951,  0.6240,\n",
       "           0.7347, -0.9325,  0.8841, -0.2864,  0.6815,  1.4812, -0.4330,  1.2707,\n",
       "          -2.9725, -0.2866, -1.5798, -0.0822, -0.3498,  0.3201, -0.6371, -1.0308,\n",
       "           0.7624,  0.7671, -0.2068, -1.1190, -2.0017, -1.2687]))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from operator import itemgetter \n",
    "\n",
    "# 假设我们有以下tensor列表以及对应的index\n",
    "tensors = [torch.randn(50), torch.randn(100), torch.randn(150), torch.randn(50), torch.randn(100)]\n",
    "tensor_lengths = [len(t) for t in tensors]\n",
    "tensor_indices = list(range(len(tensors)))\n",
    "\n",
    "# 将上述列表合并为一个列表并按照length排序\n",
    "length_index_tensors = sorted(zip(tensor_lengths, tensor_indices, tensors), key=itemgetter(0))\n",
    "\n",
    "length_index_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50,\n",
       "  [0, 3],\n",
       "  [tensor([-1.6923, -0.1544,  1.9792, -1.0376,  0.4598,  0.9939, -0.4259,  0.3254,\n",
       "           -1.0183, -0.6959,  1.8755, -0.2923,  0.1903,  1.9563,  0.2392,  0.6282,\n",
       "            0.4556,  2.2616,  0.5598, -0.1053,  0.0183,  1.8638,  1.7166, -1.6367,\n",
       "           -0.2212, -1.1999, -0.2649, -1.5602,  0.1270, -1.1239, -2.0969, -0.5352,\n",
       "            0.0666,  0.7322,  0.3686,  0.1283, -1.3826,  1.7035, -0.0280,  0.3705,\n",
       "            0.2679,  3.4676, -0.0299, -0.8803,  0.2812, -0.3721,  0.1177, -2.5318,\n",
       "            0.1107,  1.4310]),\n",
       "   tensor([ 0.3066, -0.6730, -0.4274,  1.5191,  0.9963,  0.8142, -1.2502,  1.7890,\n",
       "            0.9502, -0.9045, -0.1636,  0.9384,  0.8782,  1.8705, -1.0843, -0.2210,\n",
       "           -0.5122,  0.6798, -0.0990, -2.7825,  0.1450,  1.6235,  0.4835, -1.0989,\n",
       "           -0.1385,  1.5020,  0.6848, -0.7145, -0.3568, -0.6627, -2.4854,  0.2502,\n",
       "            1.0837,  0.6952,  0.5972, -0.7339, -0.7667,  0.6331,  3.2073, -0.5579,\n",
       "            0.4174,  1.5318, -0.9855,  1.0638,  1.8190,  0.6417, -0.2605,  1.2081,\n",
       "           -0.3126,  3.3920])]),\n",
       " (100,\n",
       "  [1, 4],\n",
       "  [tensor([-1.1530,  0.4630, -0.5929, -0.3334, -1.5337, -0.3761, -0.4264,  0.6236,\n",
       "            0.7886,  0.5523,  0.0264,  0.1156, -0.3783, -0.6941, -0.0393, -1.6394,\n",
       "           -0.5846, -0.2359, -2.0743,  0.2484, -0.2625,  0.4787, -0.3564, -0.6270,\n",
       "           -0.0405, -0.9391, -0.4962, -0.8158, -0.3366, -1.1052, -0.9559, -0.6657,\n",
       "           -1.4685,  0.5117, -0.8488, -1.2464,  1.1677, -0.1994, -0.3418,  0.1849,\n",
       "           -0.2734, -0.7778,  0.3882, -1.1622,  0.0240,  0.7290, -1.4227,  0.2744,\n",
       "           -0.7629,  0.7817,  1.9479, -0.9582,  0.3567,  0.3388,  0.8410, -0.5682,\n",
       "            0.8118,  0.4415,  1.2033, -0.5356, -0.6253,  0.2633,  0.2636, -0.3777,\n",
       "            0.2874, -1.4015,  0.0504, -0.8909, -0.8847, -0.8191, -1.6529, -1.3088,\n",
       "           -0.7258,  0.1886,  0.6368,  1.0927,  3.2895, -1.8885, -0.1930,  0.0679,\n",
       "           -0.4479, -0.1354,  1.2434,  0.8896,  0.1481,  0.9528,  1.1196, -0.6375,\n",
       "           -0.2409,  0.3265, -0.6539,  0.4064,  0.4705,  0.0406,  0.3813, -0.2769,\n",
       "            1.6197, -1.1258, -0.0280, -0.5829]),\n",
       "   tensor([-0.4289, -0.5857,  0.3087, -1.2354,  0.8339, -0.4785, -0.4903, -0.7100,\n",
       "            0.0330,  0.0095,  1.3909, -0.3980,  1.3599, -0.2485, -0.4188, -0.1988,\n",
       "           -0.4136,  0.8919, -0.7887, -0.0146, -1.3846,  0.6869,  1.6992, -1.4809,\n",
       "           -0.1995,  0.7767, -0.2773,  0.1262, -0.6973,  0.2658, -1.2218,  0.6540,\n",
       "           -0.0215,  0.1941, -0.9657, -0.8268,  0.4618, -0.8658, -0.6027, -0.2678,\n",
       "           -0.9412, -1.1018, -0.3356,  0.9398, -2.0245,  1.0160,  0.1403,  0.0909,\n",
       "            0.9410, -0.1355, -1.5521,  0.0356,  0.4971,  0.9003,  1.4676,  0.3930,\n",
       "           -0.7113,  1.3270,  0.2109,  0.3563,  1.0695,  0.5034, -1.4095,  0.4734,\n",
       "            0.7605,  1.3122, -1.1689,  0.5824,  1.0899,  1.8018,  0.6538,  0.7158,\n",
       "            0.0653, -0.7026,  0.1878,  0.2457, -1.0392, -0.1742, -0.2410, -1.4499,\n",
       "            1.4318,  1.0092,  1.7431,  0.1464, -1.0243, -0.1314, -0.0052,  0.8813,\n",
       "           -0.6435, -0.6564, -1.0936, -1.1467, -1.4814, -0.3263, -0.2972,  0.2717,\n",
       "           -1.4997,  1.3772,  0.1853, -1.0750])]),\n",
       " (150,\n",
       "  [2],\n",
       "  [tensor([ 0.4838,  0.2658,  1.3024,  0.4106,  0.7116,  0.3653,  1.2458, -0.9710,\n",
       "            0.3391, -0.1687, -0.4162,  0.6151,  0.1239, -0.8320, -0.0604, -0.1333,\n",
       "            1.2928,  1.1973, -0.3993,  1.4110, -1.8357,  0.0777,  0.4868,  0.7616,\n",
       "            0.2375,  0.4388, -1.2297,  0.7876,  0.6069,  0.7602, -0.7531,  0.3163,\n",
       "           -1.1307,  0.3194,  0.4733, -1.6075,  0.4613,  0.2316, -0.5192,  2.0695,\n",
       "           -0.3868,  1.1122, -0.6432,  1.4688, -0.2694,  0.8179,  0.2891, -0.4286,\n",
       "           -0.2077,  1.3917, -0.8775, -1.3784, -0.8770,  0.3631, -0.1439,  0.4794,\n",
       "            1.7795,  0.8811, -0.6582,  0.2229, -1.1269, -0.5766,  1.4305, -0.5890,\n",
       "            0.1710, -0.3207,  0.1703,  0.8670, -1.1666, -2.5756, -0.1512, -0.8443,\n",
       "            0.4056,  1.9162,  0.6585,  0.4617, -0.8121,  0.8601, -0.0343, -0.5251,\n",
       "           -1.3068,  0.8029,  0.8287, -1.0005, -0.3523, -0.1270, -0.9931, -0.1852,\n",
       "            1.1743,  0.6784, -0.2494,  1.3920, -0.6125, -0.0744, -0.0660,  0.8427,\n",
       "           -0.0728,  0.2515,  0.6648,  0.4393, -1.0885,  0.3600, -0.6955, -0.1181,\n",
       "           -0.2762, -0.0309, -0.7088,  2.2848, -1.0196,  1.2301,  0.1906,  0.5920,\n",
       "           -1.3232,  0.2147, -0.0989,  0.7025, -2.0134, -0.7358,  0.4744, -0.7162,\n",
       "            0.0119, -0.7050, -0.1172,  0.1502,  1.5162,  0.4613,  0.8951,  0.6240,\n",
       "            0.7347, -0.9325,  0.8841, -0.2864,  0.6815,  1.4812, -0.4330,  1.2707,\n",
       "           -2.9725, -0.2866, -1.5798, -0.0822, -0.3498,  0.3201, -0.6371, -1.0308,\n",
       "            0.7624,  0.7671, -0.2068, -1.1190, -2.0017, -1.2687])])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将同样长度的tensor分别组装为batch\n",
    "batches = []\n",
    "current_length = length_index_tensors[0][0]\n",
    "current_batch_indices = []\n",
    "current_batch_tensors = []\n",
    "for length, index, tensor in length_index_tensors:\n",
    "    if length != current_length:\n",
    "        batches.append((current_length, current_batch_indices, current_batch_tensors))\n",
    "        current_length = length\n",
    "        current_batch_indices = []\n",
    "        current_batch_tensors = []\n",
    "    current_batch_indices.append(index)\n",
    "    current_batch_tensors.append(tensor)\n",
    "batches.append((current_length, current_batch_indices, current_batch_tensors))\n",
    "\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行计算，这里的model可以替换为任何接受tensor输入，并且输出tensor的模型\n",
    "model = lambda x: x.sum(dim=0)\n",
    "outputs = []\n",
    "for length, indices, batch in batches:\n",
    "    batch_output = model(batch)\n",
    "    outputs.extend(zip(indices, batch_output))\n",
    "\n",
    "# 根据index对计算结果进行排序\n",
    "outputs.sort(key=itemgetter(0))\n",
    "final_outputs = [output for index, output in outputs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haitun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
