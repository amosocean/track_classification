{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"b\": shape (1, 234), type \"|O\">\n",
      "<HDF5 dataset \"CA\": shape (1, 175), type \"|O\">\n",
      "<HDF5 dataset \"oU\": shape (1, 238), type \"|O\">\n",
      "<HDF5 dataset \"hlb\": shape (1, 114), type \"|O\">\n",
      "<HDF5 dataset \"ayb\": shape (1, 178), type \"|O\">\n",
      "<HDF5 dataset \"hSb\": shape (1, 47), type \"|O\">\n",
      "<HDF5 dataset \"BXb\": shape (1, 190), type \"|O\">\n",
      "<HDF5 dataset \"5ic\": shape (1, 170), type \"|O\">\n",
      "<HDF5 dataset \"hCc\": shape (1, 171), type \"|O\">\n",
      "<HDF5 dataset \"BVc\": shape (1, 36), type \"|O\">\n",
      "<HDF5 dataset \"GZc\": shape (1, 232), type \"|O\">\n",
      "<HDF5 dataset \"Tpd\": shape (1, 198), type \"|O\">\n",
      "<HDF5 dataset \"gMd\": shape (1, 36), type \"|O\">\n",
      "<HDF5 dataset \"lQd\": shape (1, 247), type \"|O\">\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"lQd\": shape (1, 247), type \"|O\">"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "dir_path=\"/home/amos/haitun/pycode/\"#os.path.dirname(os.path.abspath())\n",
    "\n",
    "# Open the MATLAB v7.3 file using h5py\n",
    "dataset = h5py.File(os.path.join(dir_path,'source/matlab/savedData.mat'), 'r')\n",
    "\n",
    "# Read the dataset from the file\n",
    "sample_list = dataset['sample_list']\n",
    "for samples_ref in sample_list[0]:\n",
    "    dataset[samples_ref]\n",
    "\n",
    "dataset[samples_ref]\n",
    "# dataset_list = torch.tensor(dataset[:])\n",
    "# # Close the file\n",
    "# mat_file.close()\n",
    "\n",
    "# np.array(dataset_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(dataset.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'trajectory_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/haitun/pycode/test.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m dataframe\u001b[39m=\u001b[39mmat_contents[\u001b[39m\"\u001b[39;49m\u001b[39mtrajectory_list\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(dataframe[\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m dataframe\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mKeyError\u001b[0m: 'trajectory_list'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/amos/haitun/pycode/test.ipynb 单元格 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntudl/home/amos/haitun/pycode/test.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mtest.npy\u001b[39m\u001b[39m\"\u001b[39m,dataframe)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.save(\"test.npy\",dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'aeon.utils' from '/home/amos/anaconda3/envs/haitun/lib/python3.8/site-packages/aeon/utils/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import aeon\n",
    "X=np.ones([5,6,7])\n",
    "aeon.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:47:36.663177: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-22 14:47:36.723824: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-22 14:47:37.105119: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-22 14:47:37.107645: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-22 14:47:38.501526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_8828/1330383265.py:5: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 14:47:40.655430: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 14:47:40.655968: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-11-22 14:47:40.659256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-11-22 14:47:40.659299: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 设置GPU设备\n",
    "physical_devices = tf.config.list_physical_devices()\n",
    "tf.test.is_gpu_available()\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "# # 创建一个简单的TensorFlow模型\n",
    "# model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Dense(10, input_shape=(10,))\n",
    "# ])\n",
    "\n",
    "# # 检查是否使用GPU\n",
    "# if tf.test.is_gpu_available():\n",
    "#     print('GPU is available')\n",
    "#     # 输出当前GPU设备名称\n",
    "#     print('GPU device:', tf.test.gpu_device_name())\n",
    "# else:\n",
    "#     print('GPU is not available')\n",
    "\n",
    "# # 检查TensorFlow模型是否使用GPU\n",
    "# print('Model uses GPU:', model.layers[0].dtype == tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.15639532e+00 1.31700575e+00 3.00000000e+00 2.00000000e-01\n",
      " 0.00000000e+00 1.00000000e+00 2.00000000e+00 1.10933565e-32\n",
      " 1.96349541e+00 5.10744398e-01 2.33853577e-01 3.89048349e-01\n",
      " 2.00000000e+00 1.00000000e+00 4.00000000e+00 1.88915916e+00\n",
      " 1.00000000e+00 1.70859420e-01 0.00000000e+00 0.00000000e+00\n",
      " 2.46913580e-02 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from aeon.transformations.collection import Catch22\n",
    "from aeon.datasets import make_example_3d_numpy\n",
    "X = make_example_3d_numpy(n_cases=4, n_channels=1, n_timepoints=10,\n",
    "                          random_state=0)\n",
    "tnf = Catch22(replace_nans=True)\n",
    "tnf.fit(X)\n",
    "\n",
    "print(tnf.transform(X)[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haitun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
